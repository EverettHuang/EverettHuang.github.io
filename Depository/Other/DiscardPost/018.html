<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><title>监督学习算法：决策树及决策树集成 | Everett</title><meta name="description" content="本文简单介绍监督学习的决策数模型以及决策树集成中的随机森林模型和梯度提升回归树模型"><meta name="keywords"><meta name="author" content="Everett"><meta name="copyright" content="Everett"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/Depository/Img/WebSite/01.ico"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="canonical" href="https://EverettHuang.github.io/Depository/Other/DiscardPost/018"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:title" content="监督学习算法：决策树及决策树集成"><meta name="twitter:description" content="本文简单介绍监督学习的决策数模型以及决策树集成中的随机森林模型和梯度提升回归树模型"><meta name="twitter:image" content="https://EverettHuang.github.io/Depository/Img/WebSite/02.png"><meta property="og:type" content="website"><meta property="og:title" content="监督学习算法：决策树及决策树集成"><meta property="og:url" content="https://EverettHuang.github.io/Depository/Other/DiscardPost/018"><meta property="og:site_name" content="Everett"><meta property="og:description" content="本文简单介绍监督学习的决策数模型以及决策树集成中的随机森林模型和梯度提升回归树模型"><meta property="og:image" content="https://EverettHuang.github.io/Depository/Img/WebSite/02.png"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preload" href="/Depository/Img/Post/0013.jpg" as="image"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight_copy: 'true',
  highlight_lang: 'true',
  highlight_shrink: 'false',
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  bookmark: {
    title: 'Bookmark',
    message_prev: 'Press',
    message_next: 'to bookmark this page'
  },
  runtime_unit: 'days',
  copyright: undefined,
  copy_copyright_js: false
  
}</script></head><body><div id="header"> <div id="page-header"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">Everett</a></span><i class="fa fa-bars fa-fw toggle-menu pull-right close" aria-hidden="true"></i><span class="pull-right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div><script>document.body.addEventListener('touchstart', function(){ });</script></div></span><span class="pull-right" id="search_button"></span></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="lozad avatar_img" src="/Depository/Img/WebSite/02.png" onerror="onerror=null;src='/Depository/Img/WebSite/12.jpg'"></div><div class="mobile_post_data"><div class="mobile_data_item is_center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">18</div></a></div></div><div class="mobile_data_item is_center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">7</div></a></div></div><div class="mobile_data_item is_center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">Categories</div><div class="length_num">3</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div><script>document.body.addEventListener('touchstart', function(){ });</script></div></div></div><div id="body-wrap"><div id="web_bg"></div><nav class="not_index_bg" id="nav"><div class="nav_bg" style="background-image: url(/Depository/Img/Post/0013.jpg)"></div><div id="page_site-info"><div id="site-title"><span class="blogtitle">监督学习算法：决策树及决策树集成</span></div></div></nav><div id="content-outer"><div class="layout_page" id="content-inner"><article id="page"><h1>监督学习算法：决策树及决策树集成</h1><div class="article-container"><p><strong><center>决策树及决策树集成</center></strong></p>
<p>决策树是广泛用于分类和回归任务的模型。本质上，它是一层层的if/else问题中进行学习，并得出结论</p>
<p><strong>集成</strong>是合并多个机器学习模型来构建更强大模型的方法。在机器学习文献中有许多模型都属于这一类，但已证明有两种集成模型对大量分类和回归的数据集都是有效的，二者都以决策树为基础，分别是：<strong><a href="#01">随机森林</a></strong>和<strong><a href="#02">梯度提升回归树</a></strong></p>
<hr>
<h3 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h3><p>决策树是广泛用于分类和回归任务的模型。本质上，它是一层层的if/else问题中进行学习，并得出结论</p>
<ul>
<li><p>决策树中每个结点代表一个问题或包含答案的终结点(也叫叶结点)，如果树中某个叶结点所包含的数据点的目标值都相同，那么这个叶结点是纯的</p>
</li>
<li><p>防止决策树过拟合有两种常见策略：一种是及早停止树的生长，也叫预剪枝；另一种是先构造树，但随后删除或折叠信息量很少的结点，也叫后剪枝(或剪枝)</p>
</li>
</ul>
<p><em>预剪枝的限制条件可能包括限制树的最大深度，限制叶结点的最大数目，或者规定一个结点中数据点的最小数目来防止继续划分</em></p>
<p><strong>scikit-learn的决策树在DecisionTreeRegressor和DecisionTreeClassifier类中实现</strong></p>
<p><em>scikit-learn只实现了预剪枝，没有实现后剪枝</em></p>
<p><code>from sklearn.tree import DecisionTreeClassifier DecisionTreeRegressor</code></p>
<h4 id="DecisionTreeClassifier"><a href="#DecisionTreeClassifier" class="headerlink" title="DecisionTreeClassifier"></a>DecisionTreeClassifier</h4><p><code>from sklearn.tree import DecisionTreeClassifier</code></p>
<p><strong>方法</strong></p>
<ul>
<li>fit方法：用数据训练模型</li>
<li>predict方法：对数据用模型进行预测</li>
<li>score方法：调用该方法评估模型精度(参数为训练集时表示训练精度，参数为测试集时表示泛化精度)</li>
<li>export_graphviz函数：tree模块的export_graphviz函数，用来可视化树，这个函数会生成一个.dot文件</li>
</ul>
<p><em>可利用graphviz模块读取这个.dot文件并可视化(也可用任意读取.dot文件的程序)</em></p>
<ul>
<li>feayure_impoetances_方法：树的特征重要性，该方法为每个特征对树的决策的重要性进行排序，对于每个特征来说都介于0和1之间，0表示根本没有用到，1表示完美预测目标值。特征重要性的求和始终为1</li>
</ul>
<p><strong>参数</strong></p>
<ul>
<li>random_state：随机生成器种子，用于重现结果</li>
<li>max_depth：max_depth表示树的深度</li>
<li>max_leaf_nodes：max_leaf_nodes表示限制树的叶结点的最大数目</li>
<li>min_samples_leaf：min_samples_leaf表示规定一个叶结点数据点的最小数目</li>
</ul>
<p><strong>示例</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_breast_cancer</span><br><span class="line">----------</span><br><span class="line"><span class="comment">#用scikit-learn中的load_breast_cancer函数来加载威斯康星州乳腺癌数据集(cancer)</span></span><br><span class="line">cancer = load_breast_cancer()</span><br><span class="line"><span class="comment">#用sklearn.model_selection中的train_test_split来拆分数据</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify=cancer.target, random_state=<span class="number">42</span>)</span><br><span class="line">----------</span><br><span class="line">tree = DecisionTreeClassifier(random_state=<span class="number">0</span>)</span><br><span class="line"><span class="comment">#设置random_state参数为0来内部解决平局问题</span></span><br><span class="line">tree.fit(X_train, y_train)</span><br><span class="line"><span class="comment">#用数据训练tree模型</span></span><br><span class="line">tree.score(X_train, y_train)</span><br><span class="line"><span class="comment">#计算模型训练精度，计算得出精度为1.000</span></span><br><span class="line">tree.score(X_test, y_test)</span><br><span class="line"><span class="comment">#计算模型泛化精度，计算得出精度为0.937</span></span><br><span class="line"><span class="comment">#训练精度为100%，但泛化精度只有93.7%，表明可能存在过拟合</span></span><br><span class="line">----------</span><br><span class="line">tree = DecisionTreeClassifier(max_depth=<span class="number">4</span>, random_state=<span class="number">0</span>)</span><br><span class="line"><span class="comment">#设置max_depth=4，即设置树最大深度为4,防止过拟合</span></span><br><span class="line">tree.fit(X_train, y_train)</span><br><span class="line">tree.score(X_train, y_train)</span><br><span class="line"><span class="comment">#计算模型训练精度，计算得出精度为0.988</span></span><br><span class="line">tree.score(X_test, y_test)</span><br><span class="line"><span class="comment">#计算模型泛化精度，计算得出精度为0.951</span></span><br><span class="line"><span class="comment">#通过设置max_depth虽然降低了训练精度，但是有效提高了泛化精度</span></span><br><span class="line">----------</span><br><span class="line"><span class="comment">#利用tree中的export_graphviz函数来可视化树(该函数会生成一个.dot文件)</span></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> export_graphviz</span><br><span class="line">export_graphviz(tree, out_file=<span class="string">'tree.dot'</span>, class_name=[<span class="string">"malignant"</span>, <span class="string">"benign"</span>], feature_name=cancer.feature_name, impurity=<span class="literal">False</span>, filled=Trye)</span><br><span class="line"><span class="comment">#利用graphviz模块读取.dot文件并将其可视化(可以使用任意能够读取.dot文件的程序)</span></span><br><span class="line"><span class="keyword">import</span> graphviz</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">"tree.dot"</span>) <span class="keyword">as</span> f:</span><br><span class="line">    dot_graph = f.read()</span><br><span class="line">graphviz.Source(dot_graph)</span><br><span class="line"><span class="comment">#可视化图中每个结点的samples给出了该结点中的样本个数</span></span><br><span class="line"><span class="comment">#可视化图中每个结点的values给出的是每个类别的样本个数</span></span><br><span class="line"><span class="comment">#可视化图中每个结点的class给出的是到该结点的类别</span></span><br><span class="line">----------</span><br><span class="line">tree.feature_importances_</span><br><span class="line"><span class="comment">#特征重要性，内容为0至1的数，特征重要性的求和始终为1</span></span><br></pre></td></tr></table></figure>

<h4 id="DecisionTreeRegressor"><a href="#DecisionTreeRegressor" class="headerlink" title="DecisionTreeRegressor"></a>DecisionTreeRegressor</h4><p><code>from sklearn.tree import DecisionTreeRegressor</code></p>
<p><em>对于用于回归的决策树，所有内容都和用于分类的决策树相似</em></p>
<p><em>DecisionTreeRegressor(以及其它基于树的回归模型)不能外推，也不能在训练数据范围之外进行预测</em></p>
<h4 id="决策树优缺点"><a href="#决策树优缺点" class="headerlink" title="决策树优缺点"></a>决策树优缺点</h4><ul>
<li><p>优点：一是得到的模型很容易可视化，非专家也很容易理解(至少对于较小的树而言)；二是算法完全不受数据缩放的影响(因为每个特征被单独处理，而且数据的划分也不依赖于缩放，因此决策树算法不需要特征预处理，比如归一化或标准化)。特别是特征的尺度完全不一样时或者二元特征和连续特征同时存在时，决策树效果很好</p>
</li>
<li><p>缺点：即使做了预剪枝，决策树也经常过拟合，泛化性能很差(大叔多应用中都用决策树集成来替代单棵决策树)</p>
</li>
</ul>
<hr>
<p><span id="01"> </span></p>
<h3 id="随机森林"><a href="#随机森林" class="headerlink" title="随机森林"></a>随机森林</h3><p>随机森林本质上是多个决策树的集合，其中每棵树都和其他树略有不同，可以有效防止过拟合</p>
<p><em>1.随机森林背后的思想是，每棵树的预测可能都相对比较好，但可能对部分数据过拟合；如果构造很多树，并且每棵树的预测都很好，但都以不同的方式过拟合，那么可以对这些树的结果取平均值来降低过拟合(既能减少过拟合又能保持树的预测能力，这可以在数学上严格证明)</em></p>
<p><em>2.构造随机森林时，首先确定构造树的棵数(n_estimators参数)，然后构造每一棵树时首先对数据进行自助采样(从n_samples个数据点中有放回地重复随机抽取一个样本，共抽取n_samples次。这样会创建一个与原数据集大小相同的数据集)</em></p>
<p><em>3.用随机森林进行预测时，算法首先对森林中的每棵树进行预测。对于回归问题，对所有树的结果取平均值作为最终预测值；对于分类问题，则用软投票策略(每个算法作出软预测，给出每个可能的输出标签的概率，然后对所有树的预测概率取平均值，最后将概率最大的的类别作为预测结果)</em></p>
<p><strong>RandomForestRegressor/RandomForestClassifier</strong></p>
<ul>
<li>随机森林分类模型：from sklearn.ensemble import RandomForestClassifier</li>
<li>随机森林回归模型：from sklearn.ensemble import RandomForestRegressor</li>
</ul>
<p><strong>方法</strong></p>
<ul>
<li>fit方法：用数据训练模型</li>
<li>predict方法：对数据用模型进行预测</li>
<li>score方法：调用该方法评估模型精度(参数为训练集时表示训练精度，参数为测试集时表示泛化精度)</li>
</ul>
<p><strong>参数</strong></p>
<ul>
<li>n_estimators参数：确定构造树的棵树</li>
<li>max_features参数：随机森林算法选择特征子集时子集的特征个数</li>
<li>random_state参数：随机生成器种子，用于确定随机状态(因为森及森林本质上是随机的)(可以不设置该参数，重现结果时需要固定该参数)</li>
<li>max_depth参数：max_depth表示限制树的最大深度</li>
<li>max_leaf_nodes：max_leaf_nodes表示限制树的叶结点的最大数目</li>
<li>min_samples_leaf：min_samples_leaf表示规定一个叶结点数据点的最小数目</li>
<li>n_jobs参数：n_jobs参数调节使用的CPU内核个数，设置参数值大于内核数没有意义，设置参数值为-1则表示启用所有内核</li>
</ul>
<p><em>1.max_features参数较大，那么随机森林中的树都很相似，利用最独特的特征可以轻松拟合数据；如果max_features参数较小，那么随机森林中的树将会差异很大，为了很好地拟合数据，每棵树的深度都要很大</em></p>
<p><em>2.一般情况，对于分类默认max_features=sqrt(n_features)，对于回归默认max_features=n_features；增大max_features或max_leaf_nodes有时也可以提高性能，还可以大大降低用于训练和预测的时间和空间要求</em></p>
<p><strong>属性</strong></p>
<ul>
<li>estimator_属性：estimator_属性保存随机森林中的树</li>
</ul>
<p><em>随机森林也可以给出特征重要性，计算方法是将随机森林中所有树的特征重要性求和并取平均，一般来说随机森林给出的特征重要性要比单棵树给出的更为可靠</em></p>
<p><strong>示例</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_moons</span><br><span class="line"><span class="comment">#使用5棵树的随机森林应用到two_moons数据集</span></span><br><span class="line">X， y = make_moons(n_samples=<span class="number">100</span>, noise=<span class="number">0.25</span>, random_state=<span class="number">3</span>)</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=<span class="number">42</span>)</span><br><span class="line">forest = RandomForestClassifier(n_estimators=<span class="number">5</span>, random_state=<span class="number">2</span>)</span><br><span class="line">forest.fit(X_train, y_train)</span><br><span class="line"><span class="comment">#随机森林中的树保存在estimator_属性中</span></span><br><span class="line">----------</span><br><span class="line"><span class="comment">#将包含100课树的随机森林应用在乳腺癌数据集上</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=<span class="number">0</span>)</span><br><span class="line">forest.fit(X_train, y_train)</span><br><span class="line">forest.score(X_train, y_train)</span><br><span class="line">forest.score(X_test, y_test)</span><br><span class="line"><span class="comment">#训练精度为1.000,泛化精度为0.972；在没有任何调节下，随机森林的精度为97%，比线性模型或单棵决策树都要好</span></span><br><span class="line"><span class="comment">#可用通过调节max_features参数或预剪枝，但是随机森林的默认参数通常可以给出很好的结果</span></span><br></pre></td></tr></table></figure>

<h4 id="随机森林优缺点"><a href="#随机森林优缺点" class="headerlink" title="随机森林优缺点"></a>随机森林优缺点</h4><ul>
<li>优点：随机森林拥有决策树的所有优点，还弥补了一些缺点</li>
<li>缺点：对于维度非常高的稀疏数据(比如文本数据),随机森林表现不是很好；训练和预测速度都慢于线性模型；不便于向非专家解释模型</li>
</ul>
<hr>
<p><span id="02"> </span></p>
<h3 id="梯度提升回归树"><a href="#梯度提升回归树" class="headerlink" title="梯度提升回归树"></a>梯度提升回归树</h3><p>梯度提升回归树通过合并多个决策树来构建一个更为强大的模型(虽然名字中含有回归，但该模型既可用于回归也可用于分类)</p>
<p><em>1.如果想要将梯度提升应用在大规模问题上，可以研究一下xgboost包及其python接口，该库目前在许多数据集上的速度都比scikit-learn对梯度提升的实现要快(有时调参也更简单)</em></p>
<p><em>2.与随机森林不同，梯度提升采用连续的方式构造树，每棵树都试图纠正前一棵树的错误(默认情况下，梯度提升回归树中没有随机化，而是用到了强预剪枝)；梯度提升树通常使用深度很小(1到5之间)的树，这样模型占用内存更少，预测速度也很快</em></p>
<p><strong>GradientBoostingClassifier</strong></p>
<p><code>from sklearn.ensemble import GradientBoostingClassifier</code></p>
<p><strong>方法</strong></p>
<ul>
<li>fit方法：用数据训练模型</li>
<li>predict方法：对数据用模型进行预测</li>
<li>score方法：调用该方法评估模型精度(参数为训练集时表示训练精度，参数为测试集时表示泛化精度)</li>
</ul>
<p><strong>参数</strong></p>
<ul>
<li>learning_rate参数：学习率，用于控制每棵树对前一棵树的错误的纠正强度</li>
<li>n_estimators参数：迭代的树的数量</li>
<li>max_depth参数：max_depth表示限制树的最大深度</li>
<li>max_leaf_nodes：max_leaf_nodes表示限制树的叶结点的最大数目</li>
<li>min_samples_leaf：min_samples_leaf表示规定一个叶结点数据点的最小数目</li>
</ul>
<p><em>1.n_estimators与learning_rate参数高度相关，因为learning_rate越低，就需要更多的树来构造具有相似复杂度的模型</em></p>
<p><em>2.随机森林中n_estimators值总是越大越好，但是梯度提升不同，增大n_estimators会导致模型更加复杂，进而可能导致过拟合(通常做法是根据时间和内存的预算选择合适的n_estimators，然后对不同的learning_rate进行遍历)</em></p>
<p><em>3.通常梯度提升模型的max_depth参数都设置得很小，一般不会超过5</em></p>
<p><strong>示例</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> GradientBoostingClassifier</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=<span class="number">0</span>)</span><br><span class="line"><span class="comment">#在乳腺癌数据集上应用GradientBoostingClassifier模型，默认使用100棵树，最大深度是3,学习率为0.1</span></span><br><span class="line">gbrt = GradientBoostingClassifier(random_state=<span class="number">0</span>)</span><br><span class="line">gbrt.fit(X_train, y_train)</span><br><span class="line">gbrt.score(X_train, y_train)</span><br><span class="line">gbrt.score(X_test, y_test)</span><br><span class="line"><span class="comment">#训练精度为1.000,泛化精度为0.958</span></span><br><span class="line"><span class="comment">#由于训练精度达到100%。所以很可能存在过拟合(为了降低过拟合，我们可以限制最大深度来加强预剪枝，也可降低学习率)</span></span><br><span class="line">----------</span><br><span class="line"><span class="comment">#限制最大深度为1来加强预剪枝</span></span><br><span class="line">gbrt = GradientBoostingClassifier(random_state=<span class="number">0</span>, max_depth=<span class="number">1</span>)</span><br><span class="line">gbrt.fit(X_train, y_train)</span><br><span class="line">gbrt.score(X_train, y_train)</span><br><span class="line">gbrt.score(X_test, y_test)</span><br><span class="line"><span class="comment">#训练精度为0.991,泛化精度为0.972</span></span><br><span class="line">----------</span><br><span class="line"><span class="comment">#降低学习率为0.01</span></span><br><span class="line">gbrt = GradientBoostingClassifier(random_state=<span class="number">0</span>, learning_rate=<span class="number">0.01</span>)</span><br><span class="line">gbrt.fit(X_train, y_train)</span><br><span class="line">gbrt.score(X_train, y_train)</span><br><span class="line">gbrt.score(X_test, y_test)</span><br><span class="line"><span class="comment">#训练精度为0.988,泛化精度为0.965</span></span><br></pre></td></tr></table></figure>

<p><strong>优缺点</strong></p>
<ul>
<li>优点：梯度提升回归树是监督学习中最强大也最常用的模型之一；不需要对数据进行缩放就可以表现得很好；也适用于二元特征与连续特征同时存在的数据集</li>
<li>缺点：需要仔细调参，而且训练时间可能会比较长；与其它基于树的模型一样，通常不适用于高维稀疏数据</li>
</ul>
<hr>
</div><nav id="pagination"><div class="pagination"></div></nav></article><div class="aside_content" id="aside_content"><div class="card_widget card-author"><div class="card-content"><div class="post_data"><div class="data-item is_center"><img class="lozad avatar_img" src="/Depository/Img/WebSite/02.png" onerror="onerror=null;src='/Depository/Img/WebSite/12.jpg'"><p class="author-info__name is_center">Everett</p><p class="author-info__description is_center"></p></div></div><div class="post_data data_config"><div class="data-item is_center"><div class="data_link"><a href="/archives/"><p class="headline">Articles</p><p class="length_num">18</p></a></div></div><div class="data-item is_center">      <div class="data_link"><a href="/tags/"><p class="headline">Tags</p><p class="length_num">7</p></a></div></div><div class="data-item is_center">     <div class="data_link"><a href="/categories/"><p class="headline">Categories</p><p class="length_num">3</p></a></div></div></div><div class="post_data is_center"><a class="data-item bookmark bookmarke--primary bookmark--animated" id="bookmark-it" href="javascript:;" title="Add to bookmark"><i class="fa fa-bookmark" aria-hidden="true"></i><span>Add to bookmark</span></a></div><div class="post_data data_config"><div id="aside-social-icons"> <a class="social-icon data-item" href="https://www.facebook.com/freeeverett" target="_blank"><i class="fa fa-facebook"></i></a><a class="social-icon data-item" href="https://twitter.com/EverettFree" target="_blank"><i class="fa fa-twitter"></i></a><a class="social-icon data-item" href="https://freeeverettmail@gmail.com" target="_blank"><i class="fa fa-envelope"></i></a><a class="social-icon data-item" href="https://m.me/freeeverett" target="_blank"><i class="fa fa-comment"></i></a><a class="social-icon data-item" href="https://t.me/everetth" target="_blank"><i class="fa fa-telegram"></i></a><a class="social-icon data-item" href="https://github.com/everetthuang" target="_blank"><i class="fa fa-github"></i></a></div></div></div></div><div class="card_widget card-announcement"><div class="card-content"><div class="item_headline"><i class="fa fa-bullhorn card-announcement-animation" aria-hidden="true"></i><span>Announcement</span></div><div class="announcement_content">Thank you for visiting this site, if you like, please collect ^_^</div></div></div><div class="card_widget card-recent-post"><div class="card-content"><div class="item_headline"><i class="fa fa-history" aria-hidden="true"></i><span>Recent Post</span></div><div class="aside_recent_item"><div class="aside_recent_post"><a href="/2019/10/16/007/"><div class="aside_post_cover"><img class="aside_post_bg" src="/Depository/Img/Post/" onerror="onerror=null;src='/Depository/Img/WebSite/12.jpg'" title="Linux软件管理"></div><div id="aside_title"><div class="aside_post_title" href="/2019/10/16/007/" title="Linux软件管理">Linux软件管理</div><time class="aside_post_meta post-meta__date">2019-10-16</time></div></a></div><div class="aside_recent_post"><a href="/2019/10/15/005/"><div class="aside_post_cover"><img class="aside_post_bg" src="/Depository/Img/Post/" onerror="onerror=null;src='/Depository/Img/WebSite/12.jpg'" title="Linux存储结构与磁盘管理"></div><div id="aside_title"><div class="aside_post_title" href="/2019/10/15/005/" title="Linux存储结构与磁盘管理">Linux存储结构与磁盘管理</div><time class="aside_post_meta post-meta__date">2019-10-15</time></div></a></div><div class="aside_recent_post"><a href="/2019/10/14/004/"><div class="aside_post_cover"><img class="aside_post_bg" src="/Depository/Img/Post/" onerror="onerror=null;src='/Depository/Img/WebSite/12.jpg'" title="Linux账户与系统安全"></div><div id="aside_title"><div class="aside_post_title" href="/2019/10/14/004/" title="Linux账户与系统安全">Linux账户与系统安全</div><time class="aside_post_meta post-meta__date">2019-10-14</time></div></a></div><div class="aside_recent_post"><a href="/2019/10/13/009/"><div class="aside_post_cover"><img class="aside_post_bg" src="/Depository/Img/Post/" onerror="onerror=null;src='/Depository/Img/WebSite/12.jpg'" title="Linux系统监控"></div><div id="aside_title"><div class="aside_post_title" href="/2019/10/13/009/" title="Linux系统监控">Linux系统监控</div><time class="aside_post_meta post-meta__date">2019-10-13</time></div></a></div><div class="aside_recent_post"><a href="/2019/10/13/008/"><div class="aside_post_cover"><img class="aside_post_bg" src="/Depository/Img/Post/" onerror="onerror=null;src='/Depository/Img/WebSite/12.jpg'" title="Linux基础网络服务"></div><div id="aside_title"><div class="aside_post_title" href="/2019/10/13/008/" title="Linux基础网络服务">Linux基础网络服务</div><time class="aside_post_meta post-meta__date">2019-10-13</time></div></a></div></div></div></div><div class="card_widget card-tags"><div class="card-content"><div class="item_headline"><i class="fa fa-tags" aria-hidden="true"></i><span>Tags</span></div><div class="card-tag-cloud"><a href="/tags/Linux/" style="font-size: 24px; color: #000">Linux</a> <a href="/tags/debian/" style="font-size: 16px; color: #999">debian</a> <a href="/tags/github/" style="font-size: 16px; color: #999">github</a> <a href="/tags/github-blog/" style="font-size: 16px; color: #999">github blog</a> <a href="/tags/markdwon/" style="font-size: 16px; color: #999">markdwon</a> <a href="/tags/python/" style="font-size: 20px; color: #4d4d4d">python</a> <a href="/tags/trojan/" style="font-size: 16px; color: #999">trojan</a></div></div></div><div class="card_widget card-webinfo"><div class="card-content"><div class="item_headline"><i class="fa fa-line-chart" aria-hidden="true"></i><span>Info</span></div><div class="webinfo"><div class="webinfo_item"><div class="webinfo_article_name">Article :</div><div class="webinfo_article_count">18</div></div><div class="webinfo_item"><div class="webinfo_runtime_name">Run time :</div><div class="webinfo_runtime_count" id="webinfo_runtime_count"></div><script id="runtionshow" src="/js/runtimeshow.js" start_date="9/6/2019 00:00:00">      </script></div><div class="webinfo_item">      <div class="webinfo_site_uv_name">UV :</div><div class="webinfo_site_uv_count" id="busuanzi_value_site_uv"></div></div><div class="webinfo_item"><div class="webinfo_site_name">PV :</div><div class="webinfo_site_pv_count" id="busuanzi_value_site_pv"></div></div></div></div></div></div></div></div><footer style="background-image: url(/Depository/Img/Post/0013.jpg)"><div id="footer"><div class="copyright">&copy;2019 - 2020 By Everett</div><div class="framework-info"><span>Driven </span><a href="http://hexo.io"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme </span><a href="https://github.com/jerryc127/hexo-theme-butterfly"><span>Butterfly</span></a></div><div class="footer_custom_text">Welcome to My <a href="https://everetthuang.github.io/">Personal Home Page</a>!</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-plus" id="font_plus" title="Increase font size"></i><i class="fa fa-minus" id="font_minus" title="Decrease font size"></i><i class="nightshift fa fa-moon-o" id="nightshift" title="Dark Mode"></i></div><div id="rightside-config-show"><div id="rightside_config" title="Setting"><i class="fa fa-cog" aria-hidden="true"></i></div><i class="fa fa-arrow-up" id="go-up" title="Back to top" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/js-cookie@2/src/js.cookie.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/nightshift.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@1.2.2/instantpage.min.js" type="module"></script></body></html>