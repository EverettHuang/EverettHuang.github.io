---
title: 监督学习算法
date: 2019-10-15 17:54:59
tags: supervised learning algorithm
categories: machine learning
description: 本文主要介绍监督学习的主要算法：k近邻，线性模型，朴素贝叶斯，决策树，决策树集成(随机森林,梯度提升回归树)，核支持向量机，神经网络；以及scikit-learn监督学习中分类器的不确定度估计
cover: /Depository/Img/Post/0014.png
top_img: /Depository/Img/Post/0013.jpg
---

**<center>监督学习算法</center>**

监督学习是最常用也是最成功的机器学习类型之一

监督学习常用算法有：k近邻，线性模型，朴素贝叶斯，决策树及决策树集成(随机森林,梯度提升回归树)，核支持向量机，神经网络

*想要根据给定输入预测某个结果，并且还有输入/输出对的示例时，都应该使用监督学习*

*监督学习通常需要人力来构建训练集*

---

**分类与回归**

监督机器学习问题主要有两种，分别为**分类**(classification)与**回归**(regression)

* 分类问题的目标是预测类别标签，可分为二分类和多分类问题
* 回归任务的目标是预测一个连续值，编程术语叫做浮点数，数学术语叫做实数

---

**泛化,过拟合与欠拟合**

*在监督学习中，我们想要在训练数据上构建模型，然后能够对没有见过的新数据(这些新数据与训练集具有相同的特性)作出准确的预测*

* 如果一个模型能够对没见过的数据做出准确预测，我们就说它能够从训练集**泛化**(generalize)到测试集。

*我们想要构建一个泛化精度尽可能高的模型*

* 构建一个对现有信息量来说过于复杂的模型，被称为**过拟合**(overfitting)（过拟合往往在训练集表现很好，但在测试集表现很差）

* 构建一个对现有信息量来说过于简单的模型， 被称为**欠拟合**(underfitting)（欠拟合往往在训练集表现就很差）

*过拟合和欠拟合之间存在一个最佳位置，可以得到很好的泛化性能，即我们想要的模型*

*收集更多的数据，适当构建更复杂的模型，对监督学习任务往往特别有用(在不过拟合的前提下)*

---

**方法链**

scikit-learn中所有模型的fit方法返回的都是self，于是有如下编写代码方法

* 用一行代码初始化模型并拟合

```python
logreg = LogisticRegression().fit(X_train, y_train)
```

* 用一行代码同时使用fit和predict

```python
logreg = LogisticRegression()
y_pred = logreg.fit(X_train, y_train).predict(X_test)
```

* 一行代码完成模型初始化,拟合和预测

```python
y_pred = LogisticRegression().fit(X_train, y_train).predict(X_test)
```

*非常简短的写法并不完美，一行代码中发生了很多事，可能使代码变得难以阅读；且拟合后的回归模型也没有保存在任何变量中，我们既不能查看它也不能用它来预测其他数据*

---

**常用监督学习算法如下：**

[k近邻](https://everetthuang.github.io/2019/10/18/ml03/)

[线性模型](https://everetthuang.github.io/2019/10/18/ml04/)

[朴素贝叶斯](https://everetthuang.github.io/2019/10/18/ml09/)

[决策树及决策树集成](https://everetthuang.github.io/2019/10/18/ml05/)

[核支持向量机](https://everetthuang.github.io/2019/10/18/ml07/)

[神经网络](https://everetthuang.github.io/2019/10/18/ml08/)

[分类器的不确定度估计](https://everetthuang.github.io/2019/10/18/ml06/)

---

