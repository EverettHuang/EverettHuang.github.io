---
title: 监督学习算法：核支持向量机
date: 2019-10-18 14:22:15
tags: supervised learning algorithm
categories: machine learning
description: 本文主要介绍监督学习算法中的核支持向量机，且只介绍用于分类的情况
cover: /Depository/Img/Post/0021.jpg
top_img: /Depository/Img/Post/0013.jpg
---

**<center>核支持向量机</center>**


核技巧：该技巧可在高维空间中学习分类器，而不用实际计算可能非常大的新的数据表示

*对于支持向量机，将数据映射到更高维空间中有两种常用的方法：一是多项式核(在一定阶数内计算原始特征所有可能的多项式)，另一种是径向基函数(RBF，也叫高斯核)*

支持向量：位于类别之间边界上的那些对定义决策边界来说很重要的点称为支持向量

核支持向量机(SVM)是可以推广到更复杂模型的拓展，这些模型无法被输入空间的超平面定义

支持向量机可以同时用于分类(SVC)和回归(SVR)，但本文目前只介绍用于SVC(分类的情况)，且用高斯核

高斯核公式：

**SVC**

`from sklearn.svm import SVC`

**方法**

* fit方法：调用该方法训练模型(该方法参数为训练集)
* predict方法：调用该方法预测标签(该方法参数为待预测标签的数据)
* score方法：调用该方法评估模型R^2(返回R^2，参数为训练集时表示训练精度,参数为测试集时表示泛化精度)

**参数**

SVM的重要参数是正则化参数c，核的选择以及核相关的参数(例如RBF核的参数gamma，该参数是高斯核宽度的倒数)

* c参数：正则化参数，与线性模型中用到的类似(限制每个点的重要性，即dual_coef_)
* gamma参数：为高斯核公式中的参数，用以控制高斯核的宽度(决定了点与点之间“靠近”是指多大的距离)

*gamma参数较小，说明高斯核的半径较大，许多点都被看做比较靠近，小的gamma参数表示决策边界变化很慢，生成的是复杂度较低的模型；大的gamma参数会生成更为复杂的模型*

*c参数与线性模型中的相同，c值很小，说明模型非常受限，每个数据点的影响范围都有限，较大的c会生成较复杂的模型*

*默认情况下，c=1,gamma=1/n_features*

**属性**

* dual_coef_属性：该属性表示支持向量重要性

**示例**

```python
#在乳腺癌数据集上训练SVM(默认情况下，x=1,gamma=1/n_features)
from sklearn.svm import SVC
X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=0)
svc = SVC()
svc.fit(X_train, y_train)
svc.score(X_train, y_train)
svc.score(X_test, y_test)
#训练精度为1.00,泛化精度为0.63；说明该模型存在相当严重的过拟合；
#SVM对参数及数据过于敏感，它要求所有特征有相似的变化范围；
#乳腺癌数据特征具有完全不同的数量级，对核SVM有极大影响，所以需要对数据进行预处理(例如数据缩放)
```

**优缺点**

* 对于SVM来说，预处理数据非常重要，不进行预处理，性能可能不及其它模型

* 优点：核支持向量机是非常强大的模型，在各种数据集上的表现都很好；SVM允许决策边界很复杂，即使数据只有几个特征；在低维数据和高维数据(即很少特征和很多特征)上的表现都很好，但对样本个数的缩放表现不好
* 缺点：在多达10000个样本的数据上运行SVM可能表现良好，但数据量达到100000甚至更大，在运行时间和内存使用方面可能会面临挑战；预处理数据和调参都需要非常小心(基于树的模型则只需要很少的预处理，甚至不需要预处理)；SVM模型很难检查，很难理解为什么这么预测，很难将模型向非专家解释

*SVM仍然是值得尝试的，特别是所有特征的测量单位相似(比如都是像素密度)而且范围也差不多时*